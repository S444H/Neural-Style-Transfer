{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 代码解读"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85ae3f0e6883decb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 导入相关依赖以及选择特征层"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9359764a5e77f355"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import vgg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# from collections import OrderedDict\n",
    "import os\n",
    "from functools import reduce\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 选择\"relu4_2\" 和 \"relu5_2\" 这两个层作为内容层\n",
    "# \"relu1_1\", \"relu2_1\", \"relu3_1\", \"relu4_1\", \"relu5_1\" 这五个层作为风格层\n",
    "CONTENT_LAYERS = (\"relu4_2\", \"relu5_2\")\n",
    "STYLE_LAYERS = (\"relu1_1\", \"relu2_1\", \"relu3_1\", \"relu4_1\", \"relu5_1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:19.992426400Z",
     "start_time": "2023-12-12T18:05:19.959514600Z"
    }
   },
   "id": "bee74560b46dc38d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### from functools import reduce\n",
    "在 Python 3 中，reduce 函数从内置函数移动到了 functools 模块"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e48aea167df7f92b"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "try:\n",
    "    reduce\n",
    "except NameError:\n",
    "    from functools import reduce"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:20.027331900Z",
     "start_time": "2023-12-12T18:05:19.978462800Z"
    }
   },
   "id": "75267464df7c4b32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### def get_loss_vals(loss_store):\n",
    "从 Python 3.7 开始，普通的字典 (dict) 开始保持元素插入的顺序。\n",
    "在早期版本的 TensorFlow（如 TensorFlow 1.x）中，.eval() 方法用于在 TensorFlow 会话中执行计算图，并获得结果。但在 TensorFlow 2.x 中，可以直接使用 numpy() 或者 tf.make_ndarray() 方法将 TensorFlow 张量转换为 NumPy 数组"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6aefd6d5fb80504"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# 对 loss_store字典 中的值进行求值并返回一个新的字典\n",
    "def get_loss_vals(loss_store):\n",
    "    # return OrderedDict((key, val.eval()) for key, val in loss_store\n",
    "    return dict((key, val.numpy()) for key, val in loss_store.items())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:20.028330400Z",
     "start_time": "2023-12-12T18:05:19.995419500Z"
    }
   },
   "id": "9fd8b7e007c19ccb"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content 2\n",
      "style 5\n",
      "tv 4\n",
      "total 3\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "loss_store = dict(\n",
    "            [(\"content\", 2), (\"style\", 5), (\"tv\", 4), (\"total\", 3)]\n",
    "        )\n",
    "for key, value in loss_store.items():\n",
    "    print(key, value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:20.029327900Z",
     "start_time": "2023-12-12T18:05:20.009380200Z"
    }
   },
   "id": "ed91bd54e2a03895"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 功能函数："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "337b44d35b254233"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# 按照特定格式打印每个损失值\n",
    "def print_progress(loss_vals):\n",
    "    for key, val in loss_vals.items():\n",
    "        print(\"{:>13s} {:g}\".format(key + \" loss:\", val))\n",
    "# 将loss_vals 字典中的键与 \" loss:\" 这个字符串拼接，并进行对齐，然后输出损失值 val\n",
    "\n",
    "def _tensor_size(tensor):\n",
    "    from operator import mul\n",
    "\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)\n",
    "\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "\n",
    "def gray2rgb(gray):\n",
    "    w, h = gray.shape\n",
    "    rgb = np.empty((w, h, 3), dtype=np.float32)\n",
    "    rgb[:, :, 2] = rgb[:, :, 1] = rgb[:, :, 0] = gray\n",
    "    return rgb\n",
    "\n",
    "# 将给定的秒数以小时、分钟和秒的形式进行显示\n",
    "def hms(seconds):\n",
    "    seconds = int(seconds)\n",
    "    hours = seconds // (60 * 60)\n",
    "    minutes = (seconds // 60) % 60\n",
    "    seconds = seconds % 60\n",
    "    if hours > 0:\n",
    "        return \"%d hr %d min\" % (hours, minutes)\n",
    "    elif minutes > 0:\n",
    "        return \"%d min %d sec\" % (minutes, seconds)\n",
    "    else:\n",
    "        return \"%d sec\" % seconds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:20.044287100Z",
     "start_time": "2023-12-12T18:05:20.026334900Z"
    }
   },
   "id": "3f08407617ce2732"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 图像处理："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74771a6f264b0b05"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    img = np.array(Image.open(path)).astype(np.float32)\n",
    "    if len(img.shape) == 2:\n",
    "        # 若图像是灰度图（即通道数为 2），则将其转换为 3 通道的灰度图\n",
    "        img = np.dstack((img, img, img))\n",
    "    elif img.shape[2] == 4:\n",
    "        # 若图像是带有 Alpha 通道的 PNG 图像（即通道数为 4），则丢弃 Alpha 通道，只保留 RGB 通道\n",
    "        img = img[:, :, :3]\n",
    "    return img\n",
    "\n",
    "\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(img).save(path, quality=95)\n",
    "\n",
    "\n",
    "def imresize(arr, size):\n",
    "    img = Image.fromarray(np.clip(arr, 0, 255).astype(np.uint8))\n",
    "    if isinstance(size, tuple):\n",
    "        height, width = size\n",
    "    else:\n",
    "        width = int(img.width * size)\n",
    "        height = int(img.height * size)\n",
    "    return np.array(img.resize((width, height)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:20.082185300Z",
     "start_time": "2023-12-12T18:05:20.041294100Z"
    }
   },
   "id": "e0d7a050a5356665"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## def stylize(...)\n",
    "函数 stylize() 是一个迭代器，每次迭代会返回一个元组，包含了三个元素：迭代次数、生成图像和损失值\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77622886a8977a89"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    \n",
    "    This function yields tuples (iteration, image, loss_vals) at every\n",
    "    iteration. However `image` and `loss_vals` are None by default. Each `checkpoint_iterations`,    `image` is not None. \n",
    "     Each    `print_iterations`,      `loss_vals` is not None.\n",
    "\n",
    "    `loss_vals` is a dict with loss values for the current iteration, e.g. :\n",
    "    {'content': 1.23, 'style': 4.56, 'tv': 7.89, 'total': 13.68}\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "def stylize(\n",
    "        network,                  # 神经网络的配置文件路径\n",
    "        initial,                  # 初始图像\n",
    "        initial_noiseblend,       # 用来混合初始噪声的比例\n",
    "        content,                  # 内容图像\n",
    "        styles,                   # 风格图像s\n",
    "        \n",
    "        preserve_colors,          # 是否保持原始内容图像的亮度信息\n",
    "        iterations,               # 迭代次数\n",
    "        \n",
    "        content_weight,\n",
    "        content_weight_blend,     #  权重混合因子，用于平衡两个选定内容层的权重\n",
    "        style_weight,\n",
    "        style_layer_weight_exp,   # 指数级增加不同风格层的权重，这使得更高层的特征对风格重建的贡献更大\n",
    "        style_blend_weights,      # 风格层权重的混合权重，用于平衡不同风格图像的不同风格层的权重\n",
    "        tv_weight,                # 总变差损失的权重，总变差损失用于确保生成的图像平滑连续，避免出现噪点和过度纹理\n",
    "        \n",
    "        learning_rate,            # 优化器的学习率\n",
    "        beta1,\n",
    "        beta2,                    # Adam 优化器的超参数，用于调整梯度的指数衰减率和二次方梯度的指数衰减率\n",
    "        epsilon,                  # Adam 优化器的数值稳定性参数，用于防止除零错误\n",
    "        pooling,                  # 池化层的类型\n",
    "        print_iterations=None,\n",
    "        checkpoint_iterations=None,\n",
    "        \n",
    "        \n",
    "):\n",
    "    '''\n",
    "    对于图像数据，一般的形状表示方式是 (batch_size, height, width, channels)，其中 batch_size 是批量大小，而 height、width 和 channels 分别表示图像的高度、宽度和通道数。\n",
    "    如 content.shape 是一个包含内容图像维度信息的元组，比如 (height, width, channels)，那么这个形状元组将变成 (1, height, width, channels)。在最前面增加了一个额外的维度，这个维度大小为 1，代表一个单独的样本或者批量中的第一个样本。\n",
    "    '''\n",
    "    # 图片信息\n",
    "    shape = (1,) + content.shape\n",
    "    style_shapes = [(1,) + style.shape for style in styles]\n",
    "    \n",
    "           \n",
    "        \n",
    "    vgg_weights, vgg_mean_pixel = vgg.load_net(network) \n",
    "    \n",
    "    '''使用 Eager Execution 模式'''\n",
    "    \n",
    "    # 在前向传播模式下提取内容图像在神经网络中各层的特征\n",
    "    content_features = {} # 存储内容图像在神经网络中各层的特征值\n",
    "    # 进行预处理操作\n",
    "    content_preprocessed = vgg.preprocess(content)\n",
    "    # 定义内容图像的张量\n",
    "    content_tensor = tf.convert_to_tensor(content_preprocessed, dtype=tf.float32)\n",
    "    # 在最前面添加一个维度\n",
    "    content_1 = tf.expand_dims(content_tensor, axis=0)\n",
    "    net = vgg.net_preloaded(vgg_weights, content_1, pooling)    #---------------------------------------------------------------------------\n",
    "    # 获取特定层的输出\n",
    "    for layer_name in CONTENT_LAYERS:\n",
    "        content_features[layer_name] = net[layer_name]\n",
    "    # keras 通过模块接口使用VGG19模型\n",
    "    '''\n",
    "    content_features = {} \n",
    "    content_features = vgg.content_features(content)\n",
    "    '''\n",
    "    \n",
    "    # 在前向传播模式下提取style图像s在神经网络中各层的特征\n",
    "    style_features = [{} for _ in styles] # 列表中包含了与样式图像数量相同的字典,每个字典用于存储对应样式图像的不同层的特征信息\n",
    "    for i in range(len(styles)):\n",
    "        # 进行预处理操作\n",
    "        style_preprocessed = vgg.preprocess(styles[i])\n",
    "        # 定义内容图像的张量\n",
    "        style_tensor = tf.convert_to_tensor(style_preprocessed, dtype=tf.float32)\n",
    "        # 在最前面添加一个维度\n",
    "        style_1 = tf.expand_dims(style_tensor, axis=0)\n",
    "        net = vgg.net_preloaded(vgg_weights, style_1, pooling) #--------------------------------------------------------------------------- \n",
    "        for layer_name in STYLE_LAYERS:\n",
    "            feature = net[layer_name]\n",
    "            \n",
    "            feature = np.reshape(feature, (-1, feature.shape[3])) # 将特征张量 features 在第四个维度（RGB）上的数据重新整形为一个新的二维数组用于 gram 矩阵计算\n",
    "            gram = np.matmul(feature.T, feature) / feature.size\n",
    "            \n",
    "            style_features[i][layer_name] = gram\n",
    "\n",
    "\n",
    "\n",
    "    # 使用反向传播（backpropagation）制作风格化图像\n",
    "    initial_content_noise_coeff = 1.0 - initial_noiseblend\n",
    "    if initial is None:\n",
    "        noise = np.random.normal(size=shape, scale=np.std(content) * 0.1)\n",
    "        initial = tf.random.normal(shape) * 0.256\n",
    "    else:\n",
    "        initial = vgg.preprocess(initial)\n",
    "        initial = tf.convert_to_tensor(initial, dtype=tf.float32)  \n",
    "        initial = tf.expand_dims(initial, axis=0)\n",
    "        initial = initial * initial_content_noise_coeff + (tf.random.normal(shape) * 0.256) * (1.0 - initial_content_noise_coeff)\n",
    "    image = tf.Variable(initial) # 创建可变的张量，即变量,后续的操作中使用 image 这个变量进行图像处理、优化或者其他相关的操作\n",
    "    # net = vgg.net_preloaded(vgg_weights, image, pooling) #---------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    '''求内容损失'''\n",
    "    # 定义内容损失（content loss）中不同层的权重\n",
    "    content_layers_weights = {\"relu4_2\": content_weight_blend, \"relu5_2\": 1.0 - content_weight_blend}\n",
    "    # content_loss = vgg.calculate_content_loss(vgg_weights, image, pooling, content_features, content_weight, content_layers_weights, CONTENT_LAYERS)\n",
    "    '''\n",
    "    # 定义内容损失（content loss）中不同层的权重\n",
    "    content_layers_weights = {}\n",
    "    content_layers_weights[\"relu4_2\"] = content_weight_blend\n",
    "    content_layers_weights[\"relu5_2\"] = 1.0 - content_weight_blend\n",
    "    \n",
    "    content_loss = 0\n",
    "    content_losses = []\n",
    "    for content_layer in CONTENT_LAYERS:\n",
    "        content_losses.append(\n",
    "                content_layers_weights[content_layer] * content_weight\n",
    "                * (\n",
    "                    2  #  \"gradient normalization\"（梯度归一化），通过乘以一个常数（如这里的 2），可以调整损失函数的梯度，从而影响优化算法的收敛速度和稳定性，具体的常数值可能是根据实验或经验得出的，用于调整优化过程中的梯度\n",
    "                    * tf.nn.l2_loss(net[content_layer] - content_features[content_layer])  # 使用了 L2 范数（欧几里得距离）来衡量生成图像和目标内容图像之间的差异\n",
    "                    / _tensor_size(content_features[content_layer])\n",
    "                  )\n",
    "                             )\n",
    "    content_loss += reduce(tf.add, content_losses)\n",
    "    '''\n",
    "    \n",
    "    '''求风格损失'''\n",
    "    # 使用 style_layer_weight_exp 定义style_layer各层weight，并进行归一占比（normalize）\n",
    "    layer_weight = 1.0\n",
    "    style_layers_weights = {}\n",
    "    for style_layer in STYLE_LAYERS:\n",
    "        style_layers_weights[style_layer] = layer_weight\n",
    "        layer_weight *= style_layer_weight_exp\n",
    "    # normalize style layer weights ，指数级增加不同风格层的权重，这使得更高层的特征对风格重建的贡献更大\n",
    "    layer_weights_sum = 0\n",
    "    for style_layer in STYLE_LAYERS:\n",
    "        layer_weights_sum += style_layers_weights[style_layer]\n",
    "    for style_layer in STYLE_LAYERS:\n",
    "        style_layers_weights[style_layer] /= layer_weights_sum\n",
    "    \n",
    "    # style_loss = vgg.calculate_style_loss(vgg_weights, image, pooling, style_layers_weights, style_features, styles, style_weight, style_blend_weights, STYLE_LAYERS)\n",
    "    \n",
    "    '''\n",
    "    style_loss = 0\n",
    "    for i in range(len(styles)):\n",
    "        style_losses = []\n",
    "        for style_layer in STYLE_LAYERS:\n",
    "            \n",
    "            layer = net[style_layer]\n",
    "            _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
    "            size = height * width * number\n",
    "            \n",
    "            feats = tf.reshape(layer, (-1, number))\n",
    "            gram = tf.matmul(tf.transpose(feats), feats) / size\n",
    "            \n",
    "            style_gram = style_features[i][style_layer]\n",
    "            style_gram_tensor = tf.convert_to_tensor(style_gram, dtype=tf.float32) # 张量\n",
    "            \n",
    "            style_losses.append(\n",
    "                    style_layers_weights[style_layer]\n",
    "                    * 2\n",
    "                    * tf.nn.l2_loss(gram - style_gram_tensor)\n",
    "                    / _tensor_size(style_gram_tensor)\n",
    "                               )\n",
    "        style_loss += style_weight * style_blend_weights[i] * reduce(tf.add, style_losses)\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    '''总变差损失'''    \n",
    "    # 总变差去噪:用于减少图像噪声和保持图像细节\n",
    "    '''\n",
    "    tv_y_size = _tensor_size(image[:, 1:, :, :])\n",
    "    tv_x_size = _tensor_size(image[:, :, 1:, :])\n",
    "    tv_loss = (\n",
    "            tv_weight\n",
    "            * 2\n",
    "            * (\n",
    "                (tf.nn.l2_loss(image[:, 1:, :, :] - image[:, : shape[1] - 1, :, :]) / tv_y_size)\n",
    "                + (tf.nn.l2_loss(image[:, :, 1:, :] - image[:, :, : shape[2] - 1, :]) / tv_x_size)\n",
    "            )\n",
    "        )\n",
    "    '''\n",
    "    # tv_loss = vgg.tv_loss(image, tv_weight, shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    # optimizer setup\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate, beta1, beta2, epsilon)\n",
    "    # optimization\n",
    "    best_loss = float(\"inf\")\n",
    "    best = None\n",
    "    iteration_times = []\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Optimization started...\")\n",
    "     \n",
    "    for i in range(iterations):\n",
    "        iteration_start = time.time()\n",
    "        if i > 0:\n",
    "            elapsed = time.time() - start\n",
    "            remaining = np.mean(iteration_times[-10:]) * (iterations - i)\n",
    "            print('第{0}次迭代，已训练时间：{1}，预计还剩时间：{2}'.format(i + 1, hms(elapsed), hms(remaining)))\n",
    "        else:\n",
    "            print('第{0}次迭代，共需迭代数：{1}'.format(i + 1,iterations))\n",
    "            \n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            content_loss = vgg.calculate_content_loss(vgg_weights, image, pooling, content_features, content_weight, content_layers_weights, CONTENT_LAYERS)\n",
    "            style_loss = vgg.calculate_style_loss(vgg_weights, image, pooling, style_layers_weights, style_features, styles, style_weight, \n",
    "                         style_blend_weights, STYLE_LAYERS)\n",
    "            tv_loss = vgg.tv_loss(image, tv_weight, shape)\n",
    "            loss = content_loss + style_loss + tv_loss\n",
    "            loss_store = dict([(\"content\", content_loss), (\"style\", style_loss), (\"tv\", tv_loss), (\"total\", loss)])\n",
    "        # 计算损失相对于变量（这里是图像）的梯度\n",
    "        gradients = tape.gradient(loss, image)\n",
    "        # 应用梯度更新图像\n",
    "        optimizer.apply_gradients(zip(gradients, [image]))\n",
    "        \n",
    "        if print_iterations and print_iterations != 0:\n",
    "            print_progress(get_loss_vals(loss_store))\n",
    "        # 控制何时打印损失值进度信息\n",
    "        last_step = (i == iterations - 1)\n",
    "        if last_step or (print_iterations and i % print_iterations == 0):\n",
    "            loss_vals = get_loss_vals(loss_store)\n",
    "            print_progress(loss_vals)\n",
    "        else:\n",
    "            loss_vals = None\n",
    "            \n",
    "         # 是否达到检查点,定期保存训练过程中的状态               \n",
    "        if (checkpoint_iterations and i % checkpoint_iterations == 0) or last_step:\n",
    "            this_loss = loss\n",
    "            if this_loss < best_loss:\n",
    "                best_loss = this_loss\n",
    "                best = image\n",
    "            img_out = vgg.unprocess(best.reshape(shape[1:]))\n",
    "            # 保持原始内容图像的亮度信息，而使用风格化图像的色彩和纹理信息\n",
    "            if preserve_colors:\n",
    "                original_image = np.clip(content, 0, 255)\n",
    "                styled_image = np.clip(img_out, 0, 255)\n",
    "\n",
    "                # Luminosity transfer steps:\n",
    "                # 1. Convert stylized RGB->grayscale accoriding to Rec.601 luma (0.299, 0.587, 0.114)\n",
    "                # 2. Convert stylized grayscale into YUV (YCbCr)\n",
    "                # 3. Convert original image into YUV (YCbCr)\n",
    "                # 4. Recombine (stylizedYUV.Y, originalYUV.U, originalYUV.V)\n",
    "                # 5. Convert recombined image from YUV back to RGB\n",
    "\n",
    "                # 1\n",
    "                styled_grayscale = rgb2gray(styled_image)\n",
    "                styled_grayscale_rgb = gray2rgb(styled_grayscale)\n",
    "\n",
    "                # 2\n",
    "                styled_grayscale_yuv = np.array(Image.fromarray(styled_grayscale_rgb.astype(np.uint8)).convert(\"YCbCr\"))\n",
    "\n",
    "                # 3\n",
    "                original_yuv = np.array(Image.fromarray(original_image.astype(np.uint8)).convert(\"YCbCr\"))\n",
    "\n",
    "                # 4\n",
    "                w, h, _ = original_image.shape\n",
    "                combined_yuv = np.empty((w, h, 3), dtype=np.uint8)\n",
    "                combined_yuv[..., 0] = styled_grayscale_yuv[..., 0]\n",
    "                combined_yuv[..., 1] = original_yuv[..., 1]\n",
    "                combined_yuv[..., 2] = original_yuv[..., 2]\n",
    "\n",
    "                # 5\n",
    "                img_out = np.array(Image.fromarray(combined_yuv, \"YCbCr\").convert(\"RGB\"))\n",
    "            \n",
    "            else:\n",
    "                img_out = None\n",
    "            yield i + 1 if last_step else i,    img_out, loss_vals\n",
    "\n",
    "            iteration_end = time.time()\n",
    "            iteration_times.append(iteration_end - iteration_start)\n",
    "\n",
    "                    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:20.092159200Z",
     "start_time": "2023-12-12T18:05:20.073211100Z"
    }
   },
   "id": "d152741b8b116242"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "network = '../imagenet-vgg-verydeep-19.mat'\n",
    "image =imread('../sucai/style_1.png')\n",
    "image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "# 在最前面添加一个维度\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "vgg_weights, vgg_mean_pixel = vgg.load_net(network) \n",
    "net = vgg.net_preloaded(vgg_weights, image, \"avg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:05:23.017901Z",
     "start_time": "2023-12-12T18:05:20.086174800Z"
    }
   },
   "id": "2370159a4e8329b7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b0eabd8b2ab048"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
